{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization of Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsnumpy import load_data, data_processing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data1 = \"./data/bybit_candle_btc_1h.csv\"\n",
    "data2 = \"./data/cryptoquant_btc_coinbase-premium-index_1h.csv\"\n",
    "factor = 'coinbase_premium_index'\n",
    "\n",
    "unselected_df = load_data(data1, data2)\n",
    "df = unselected_df[[\"start_time\", \"close\", factor]].copy()\n",
    "df.columns = [\"start_time\", \"close\", factor]\n",
    "df = data_processing(df, \"diff\", factor)\n",
    "# df = data_processing(df, \"cbrt\", factor)\n",
    "\n",
    "# Visualize the raw data of factor do not need close price\n",
    "fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "ax1.plot(df['start_time'], df[factor], label=factor, color='green', linewidth=2)\n",
    "ax1.set_xlabel(\"Date\", fontsize=12)\n",
    "ax1.set_ylabel(factor, fontsize=12, color='green')\n",
    "ax1.tick_params(axis='y', labelcolor='green')\n",
    "# Add title and grid\n",
    "plt.title(f\"Raw Data of {factor}\", fontsize=16)\n",
    "fig.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Backtest + show heatmap of Split backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from utilsnumpy import backtest , load_data, load_single_data, combine_factors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "annualizer_dict = {\n",
    "    '1m': 525600,  # 1-minute intervals in a year\n",
    "    '5m': 105120,  # 5-minute intervals in a year\n",
    "    '15m': 35040,  # 15-minute intervals in a year\n",
    "    '30m': 17520,  # 30-minute intervals in a year\n",
    "    '1h': 8760,    # 1-hour intervals in a year\n",
    "    '4h': 2190,    # 4-hour intervals in a year\n",
    "    '1d': 365,     # 1-day intervals in a year\n",
    "    '1w': 52,      # 1-week intervals in a year\n",
    "    '1M': 12       # 1-month intervals in a year\n",
    "}\n",
    "\n",
    "all_backtest_results = []\n",
    "plot_data = []\n",
    "\n",
    "def main(data1, data2, data3, factor, factor2, interval, operation,preprocess, model, entry, window_end, window_step, threshold_end, threshold_step):\n",
    "    # Load data\n",
    "    unselected_df = load_data(data1, data2)\n",
    "    # Select wanted data column\n",
    "    df = unselected_df[[\"start_time\", \"close\", factor]].copy()\n",
    "    # rename data column\n",
    "    df.columns = [\"start_time\", \"close\", factor]\n",
    "\n",
    "    # Load data3 if operation sign provided\n",
    "    if operation != 'none':\n",
    "        df1 = load_single_data(data3, factor2)\n",
    "        # Merge df and df1\n",
    "        df = pd.merge_asof(df, df1.sort_values('start_time'), on=\"start_time\", direction=\"nearest\")\n",
    "        df, new_column_name = combine_factors(df, factor, factor2, operation)\n",
    "        factor = new_column_name\n",
    "    # print(df.columns)\n",
    "    # print(factor)\n",
    "\n",
    "    # metrics setting\n",
    "    window_start= 5\n",
    "    threshold_start = 0.0\n",
    "    annualizer = annualizer_dict.get(interval, None) # Day data, so 365\n",
    "    train_split = annualizer * 3\n",
    "    \n",
    "    backtest_report = []\n",
    "\n",
    "    # Split data into train and test sets (Train set: 3Year, Test set use remaining data)\n",
    "    df_train = df[:train_split].reset_index(drop=True).copy()\n",
    "    # df_test = df[train_split:].reset_index(drop=True).copy()\n",
    "\n",
    "    # backtest\n",
    "    for rolling_window in range(window_start, window_end, window_step):\n",
    "        for threshold in np.arange(threshold_start, threshold_end, threshold_step):\n",
    "            backtest_report.append(backtest(df_train, rolling_window, threshold, preprocess, entry, annualizer, model, factor, interval, \"sr\"))\n",
    "    all_backtest_results.append(backtest_report)\n",
    "    \n",
    "\n",
    "    # Extract pivot table for SR to plot heatmap\n",
    "    backtest_df = pd.DataFrame(backtest_report)\n",
    "    plot_data.append((model, entry, backtest_df))\n",
    "\n",
    "def plot_heatmaps(sr_threshold=1.5):\n",
    "    for model, entry, backtest_df in plot_data:\n",
    "        # ✅ Optimized pivot using groupby instead of pivot\n",
    "        sr_pivot_data = backtest_df.groupby(['rolling_window', 'threshold'])['SR'].mean().unstack()\n",
    "\n",
    "        # ✅ Dynamically set SR threshold based on entry name\n",
    "        sr_threshold = 1.2 if entry.startswith('S') else sr_threshold  # Use 1.2 for entries starting with 'S', otherwise 1.8\n",
    "\n",
    "        # ✅ Check if the entire heatmap is NaN\n",
    "        if sr_pivot_data.isna().all().all():\n",
    "            print(f\"⚠️ Skipping {model}_{entry} heatmap: All SR values are NaN.\")\n",
    "            continue  # Skip plotting\n",
    "\n",
    "        # ✅ Check if there is at least one SR > threshold\n",
    "        if not np.any(sr_pivot_data.to_numpy() > sr_threshold):\n",
    "            print(f\"⚠️ Skipping {model}_{entry} heatmap: No SR value exceeds {sr_threshold}.\")\n",
    "            continue  # Skip plotting\n",
    "\n",
    "        plt.figure(figsize=(18, 14))  # ✅ Reduced figure size for faster rendering\n",
    "        sns.heatmap(sr_pivot_data, annot=True, fmt=\".2f\", cmap=\"RdYlGn\", linewidths=0.3, cbar_kws={'label': 'Sharpe Ratio'})\n",
    "        plt.title(f\"{model}_{preprocess}_{entry} Train Period BackTest SR Heatmap\", fontsize=14)\n",
    "        plt.show()  # ✅ Display the plot\n",
    "        plt.close()  # ✅ Free memory after each plot\n",
    "\n",
    "# models = ['zscore', 'momentum', 'volatility', 'robust', 'sma_diff', 'ewm', 'minmax', 'percentile', 'maxabs', 'mean_norm', 'roc', 'rsi', 'psy', 'rvi', 'mad', 'ma_ratio']\n",
    "# entrys = ['Trend', 'Trend_Reverse', 'MR', 'MR_Reverse', 'Trend_NoHold',  'Trend_emaFilter', 'Trend_NoHold_emaFilter', \n",
    "#            'L_Trend', 'L_Trend_Reverse', 'L_MR', 'L_MR_Reverse', 'L_Trend_NoHold', 'L_Trend_emaFilter', 'L_Trend_NoHold_emaFilter', \n",
    "#            'S_Trend', 'S_Trend_Reverse', 'S_MR', 'S_MR_Reverse' ,'S_Trend_NoHold', 'S_Trend_emaFilter', 'S_Trend_NoHold_emaFilter']\n",
    "\n",
    "models = ['robust']\n",
    "entrys = ['Trend_Reverse', 'MR_Reverse', 'L_Trend_Reverse', 'L_Trend_emaFilter']\n",
    "           \n",
    "factor = 'inflow_total'\n",
    "factor2 = 'netflow_total'\n",
    "interval = '1d'\n",
    "operation = '/'\n",
    "preprocess = 'diff'\n",
    "total_combinations = len(models) * len(entrys)\n",
    "for model, entry in tqdm(product(models, entrys), \n",
    "                        total=total_combinations,\n",
    "                        desc=\"🔍 Backtesting Strategies\",\n",
    "                        unit=\"strategy\", \n",
    "                        leave = True):\n",
    "    main(\n",
    "        f\"./data/bybit_candle_btc_{interval}.csv\",\n",
    "        f\"./data/cryptoquant_btc_inflow_{interval}.csv\",\n",
    "        f\"./data/cryptoquant_btc_netflow_{interval}.csv\",\n",
    "        factor,\n",
    "        factor2,\n",
    "        interval,\n",
    "        operation,\n",
    "        preprocess,\n",
    "        model,\n",
    "        entry,\n",
    "        window_end=201,\n",
    "        window_step=5,\n",
    "        threshold_end=3.01,\n",
    "        threshold_step=0.1\n",
    ")\n",
    "\n",
    "# ✅ Plot all heatmaps that SR > 1.5after backtesting\n",
    "plot_heatmaps(1.5)\n",
    "   \n",
    "# Output backtest json file with all model and entry\n",
    "# output_filename = f\"{factor}_{interval}_split_backtest.json\" \n",
    "# output_backtest_data = {\"backtests\": all_backtest_results}\n",
    "# with open(output_filename, \"w\") as json_file:\n",
    "#     json.dump(output_backtest_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot SR HeatMap by input model name(From backtest json file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load JSON file\n",
    "def load_json(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data[\"backtests\"]\n",
    "\n",
    "# Extract SR data grouped by backtest_mode\n",
    "def extract_sr_data(backtests, model):\n",
    "    sr_data_dict = {}\n",
    "    \n",
    "    for backtest_list in backtests:\n",
    "        for bt in backtest_list:\n",
    "            if bt[\"model\"] == model:\n",
    "                mode = bt[\"backtest_mode\"]\n",
    "                if mode not in sr_data_dict:\n",
    "                    sr_data_dict[mode] = []\n",
    "                sr_data_dict[mode].append((bt[\"rolling_window\"], bt[\"threshold\"], bt[\"SR\"]))\n",
    "\n",
    "    return sr_data_dict\n",
    "\n",
    "# Create heatmaps for each backtest_mode\n",
    "def plot_sr_heatmaps(sr_data_dict, model):\n",
    "    if not sr_data_dict:\n",
    "        print(\"No data found for the given model.\")\n",
    "        return\n",
    "\n",
    "    for mode, sr_data in sr_data_dict.items():\n",
    "        df = pd.DataFrame(sr_data, columns=[\"rolling_window\", \"threshold\", \"SR\"])\n",
    "        pivot_table = df.pivot(index=\"rolling_window\", columns=\"threshold\", values=\"SR\")\n",
    "        \n",
    "        plt.figure(figsize=(20,16))\n",
    "        sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"RdYlGn\", linewidths=0.5, cbar_kws={'label': 'Sharpe Ratio'})\n",
    "        plt.title(f\"Train Period BackTest Sharpe Ratio Heatmap - {mode} ({model})\")\n",
    "        plt.xlabel(\"Rolling Window\")\n",
    "        plt.ylabel(\"Threshold\")\n",
    "        plt.show()\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    file_path = \"mvrv_1d_split_backtest.json\"  # Update with actual file path\n",
    "    model = \"zscore\"\n",
    "    \n",
    "    backtests = load_json(file_path)\n",
    "    sr_data_dict = extract_sr_data(backtests, model)\n",
    "    plot_sr_heatmaps(sr_data_dict, model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Forward Testing Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsnumpy import backtest , load_data, load_single_data, combine_factors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import talib\n",
    "import math\n",
    "import json\n",
    "\n",
    "annualizer_dict = {\n",
    "    '1m': 525600,  # 1-minute intervals in a year\n",
    "    '5m': 105120,  # 5-minute intervals in a year\n",
    "    '15m': 35040,  # 15-minute intervals in a year\n",
    "    '30m': 17520,  # 30-minute intervals in a year\n",
    "    '1h': 8760,    # 1-hour intervals in a year\n",
    "    '4h': 2190,    # 4-hour intervals in a year\n",
    "    '1d': 365,     # 1-day intervals in a year\n",
    "    '1w': 52,      # 1-week intervals in a year\n",
    "    '1M': 12       # 1-month intervals in a year\n",
    "}\n",
    "\n",
    "def main(data1, data2, data3, factor, factor2, interval, operation, preprocess, model, entry, window, threshold):\n",
    "    # Merge Data\n",
    "    unselected_df = load_data(data1, data2)\n",
    "    # Select wanted data column\n",
    "    df = unselected_df[[\"start_time\", \"close\", factor]].copy()\n",
    "    # rename column\n",
    "    df.columns = [\"start_time\", \"close\", factor]\n",
    "    \n",
    "    # Load data3 if operation sign provided\n",
    "    if operation != 'none':\n",
    "        df1 = load_single_data(data3, factor2)\n",
    "        # Merge df and df1\n",
    "        df = pd.merge_asof(df, df1.sort_values('start_time'), on=\"start_time\", direction=\"nearest\")\n",
    "        df, new_column_name = combine_factors(df, factor, factor2, operation)\n",
    "        factor = new_column_name\n",
    "    \n",
    "    # metrics setting\n",
    "    rolling_window = window\n",
    "    threshold = threshold\n",
    "    annualizer = annualizer_dict.get(interval, None) # Day data, so 365\n",
    "    train_split = annualizer * 3\n",
    "\n",
    "    # Split data into train and test sets (Train set: 3Year, Test set use remaining data)\n",
    "    # df_train = df[:train_split].reset_index(drop=True).copy()\n",
    "    df_test = df[train_split:].reset_index(drop=True).copy()\n",
    "\n",
    "    forwardtest_report = []\n",
    "    forwardtest_report.append(backtest(df_test, rolling_window, threshold, preprocess, entry, annualizer, model, factor, interval))\n",
    "\n",
    "    print(json.dumps(forwardtest_report, indent=4))\n",
    "    \n",
    "\n",
    "    # Plot close price on the left y-axis\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "    ax1.plot(df_test['start_time'], df_test['close'], label='Close Price', color='green', linewidth=2)\n",
    "    ax1.set_xlabel(\"Date\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Close Price\", fontsize=12, color='green')\n",
    "    ax1.tick_params(axis='y', labelcolor='green')\n",
    "    # Plot cumulative PnL on the right y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(df_test['start_time'], df_test['cumu_pnl'], label='Cumulative PnL', color='blue', linewidth=2)\n",
    "    ax2.set_ylabel(\"Cumulative PnL\", fontsize=12, color='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "    # Add title and grid\n",
    "    plt.title(\"Close Price and Cumulative PnL Plot (Forward Test Period)\", fontsize=16)\n",
    "    fig.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # output_forwardtest_data = {\"forward_test\": forwardtest_report}\n",
    "    # with open(f\"final_{factor}_{interval}_forward_test.json\", \"w\") as json_file:\n",
    "    #     json.dump(output_forwardtest_data, json_file, indent=4)\n",
    "    \n",
    "    # Export df to csv\n",
    "    # df.to_csv(\"backtest_df.csv\", index=False)\n",
    "\n",
    "factor = 'inflow_total'\n",
    "factor2 = 'netflow_total'\n",
    "interval = '1d'\n",
    "operation = '/'\n",
    "preprocess = 'diff'\n",
    "model = 'zscore'\n",
    "entry = 'L_Trend'\n",
    "window=25\n",
    "threshold=1.4\n",
    "\n",
    "main(\n",
    "    f\"./data/bybit_candle_btc_{interval}.csv\",\n",
    "    f\"./data/cryptoquant_btc_open-interest_{interval}.csv\",\n",
    "    f\"./data/cryptoquant_btc_netflow_{interval}.csv\",\n",
    "    factor,\n",
    "    factor2,\n",
    "    interval,\n",
    "    operation,\n",
    "    preprocess,\n",
    "    model,\n",
    "    entry,\n",
    "    window,\n",
    "    threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train backtest (For cumuPNL Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsnumpy import backtest , load_data, load_single_data, combine_factors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import talib\n",
    "import math\n",
    "import json\n",
    "\n",
    "annualizer_dict = {\n",
    "    '1m': 525600,  # 1-minute intervals in a year\n",
    "    '5m': 105120,  # 5-minute intervals in a year\n",
    "    '15m': 35040,  # 15-minute intervals in a year\n",
    "    '30m': 17520,  # 30-minute intervals in a year\n",
    "    '1h': 8760,    # 1-hour intervals in a year\n",
    "    '4h': 2190,    # 4-hour intervals in a year\n",
    "    '1d': 365,     # 1-day intervals in a year\n",
    "    '1w': 52,      # 1-week intervals in a year\n",
    "    '1M': 12       # 1-month intervals in a year\n",
    "}\n",
    "\n",
    "def main(data1, data2, data3, factor, factor2, interval, operation, preprocess, model, entry, window, threshold):\n",
    "    # Merge Data\n",
    "    unselected_df = load_data(data1, data2)\n",
    "    # Select wanted data column\n",
    "    df = unselected_df[[\"start_time\", \"close\", factor]].copy()\n",
    "    # rename column\n",
    "    df.columns = [\"start_time\", \"close\", factor]\n",
    "    \n",
    "    # Load data3 if operation sign provided\n",
    "    if operation != 'none':\n",
    "        df1 = load_single_data(data3, factor2)\n",
    "        # Merge df and df1\n",
    "        df = pd.merge_asof(df, df1.sort_values('start_time'), on=\"start_time\", direction=\"nearest\")\n",
    "        df, new_column_name = combine_factors(df, factor, factor2, operation)\n",
    "        factor = new_column_name    \n",
    "    # metrics setting\n",
    "    rolling_window = window\n",
    "    threshold = threshold\n",
    "    annualizer = annualizer_dict.get(interval, None)\n",
    "    train_split = annualizer * 3\n",
    "\n",
    "    # Split data into train and test sets (Train set: 3Year, Test set use remaining data)\n",
    "    df_train = df[:train_split].reset_index(drop=True).copy()\n",
    "    # df_test = df[train_split:].reset_index(drop=True).copy()\n",
    "\n",
    "    forwardtest_report = []\n",
    "    forwardtest_report.append(backtest(df_train, rolling_window, threshold, preprocess, entry, annualizer, model, factor, interval))\n",
    "\n",
    "    print(json.dumps(forwardtest_report, indent=4))\n",
    "    \n",
    "\n",
    "    # Plot close price on the left y-axis\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "    ax1.plot(df_train['start_time'], df_train['close'], label='Close Price', color='green', linewidth=2)\n",
    "    ax1.set_xlabel(\"Date\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Close Price\", fontsize=12, color='green')\n",
    "    ax1.tick_params(axis='y', labelcolor='green')\n",
    "    # Plot cumulative PnL on the right y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(df_train['start_time'], df_train['cumu_pnl'], label='Cumulative PnL', color='blue', linewidth=2)\n",
    "    ax2.set_ylabel(\"Cumulative PnL\", fontsize=12, color='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "    # Add title and grid\n",
    "    plt.title(\"Close Price and Cumulative PnL Plot (Split Train Period)\", fontsize=16)\n",
    "    fig.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Export df to csv\n",
    "    # df.to_csv(\"backtest_df.csv\", index=False)\n",
    "\n",
    "factor = 'inflow_total'\n",
    "factor2 = 'netflow_total'\n",
    "interval = '1d'\n",
    "operation = '/'\n",
    "preprocess = 'diff'\n",
    "model = 'zscore'\n",
    "entry = 'L_Trend'\n",
    "window=25\n",
    "threshold=1.4\n",
    "\n",
    "main(\n",
    "    f\"./data/bybit_candle_btc_{interval}.csv\",\n",
    "    f\"./data/cryptoquant_btc_open-interest_{interval}.csv\",\n",
    "    f\"./data/cryptoquant_btc_netflow_{interval}.csv\",\n",
    "    factor,\n",
    "    factor2,\n",
    "    interval,\n",
    "    operation,\n",
    "    preprocess,\n",
    "    model,\n",
    "    entry,\n",
    "    window,\n",
    "    threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest(No Permutation)(HandTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsnumpy import backtest , load_data, load_single_data, combine_factors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import talib\n",
    "import math\n",
    "import json\n",
    "import modin\n",
    "\n",
    "annualizer_dict = {\n",
    "    '1m': 525600,  # 1-minute intervals in a year\n",
    "    '5m': 105120,  # 5-minute intervals in a year\n",
    "    '15m': 35040,  # 15-minute intervals in a year\n",
    "    '30m': 17520,  # 30-minute intervals in a year\n",
    "    '1h': 8760,    # 1-hour intervals in a year\n",
    "    '4h': 2190,    # 4-hour intervals in a year\n",
    "    '1d': 365,     # 1-day intervals in a year\n",
    "    '1w': 52,      # 1-week intervals in a year\n",
    "    '1M': 12       # 1-month intervals in a year\n",
    "}\n",
    "\n",
    "def main(data1, data2, data3, factor, factor2, interval, operation, preprocess, model, entry, window, threshold):\n",
    "    # Merge Data\n",
    "    unselected_df = load_data(data1, data2)\n",
    "    # Select wanted data column\n",
    "    df = unselected_df[[\"start_time\", \"close\", factor]].copy()\n",
    "    # rename column\n",
    "    df.columns = [\"start_time\", \"close\", factor]\n",
    "    \n",
    "    # Load data3 if operation sign provided\n",
    "    if operation != 'none':\n",
    "        df1 = load_single_data(data3, factor2)\n",
    "        # Merge df and df1\n",
    "        df = pd.merge_asof(df, df1.sort_values('start_time'), on=\"start_time\", direction=\"nearest\")\n",
    "        df, new_column_name = combine_factors(df, factor, factor2, operation)\n",
    "        factor = new_column_name\n",
    "        \n",
    "    # metrics setting\n",
    "    rolling_window = window\n",
    "    threshold = threshold\n",
    "    annualizer = annualizer_dict.get(interval, None) # Day data, so 365\n",
    "\n",
    "    backtest_report = []\n",
    "    backtest_report.append(backtest(df, rolling_window, threshold, preprocess, entry, annualizer, model, factor, interval))\n",
    "\n",
    "    print(json.dumps(backtest_report, indent=4))\n",
    "\n",
    "    # Plot close price on the left y-axis\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "    ax1.plot(df['start_time'], df['close'], label='Close Price', color='green', linewidth=2)\n",
    "    ax1.set_xlabel(\"Date\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Close Price\", fontsize=12, color='green')\n",
    "    ax1.tick_params(axis='y', labelcolor='green')\n",
    "    # Plot cumulative PnL on the right y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(df['start_time'], df['cumu_pnl'], label='Cumulative PnL', color='blue', linewidth=2)\n",
    "    ax2.set_ylabel(\"Cumulative PnL\", fontsize=12, color='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "    # Add title and grid\n",
    "    plt.title(\"Close Price and Cumulative PnL Plot (Full Length)\", fontsize=16)\n",
    "    fig.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Export df to csv\n",
    "    # df.to_csv(\"backtest_df.csv\", index=False)\n",
    "    # df.to_csv(f\"./liveRunning/excel_for_each_backtest/{factor}_{preprocess}_{interval}_{model}_{entry}_{window}_{threshold}.csv\", index=False)\n",
    "\n",
    "factor = 'inflow_total'\n",
    "factor2 = 'netflow_total'\n",
    "interval = '1d'\n",
    "operation = '/'\n",
    "preprocess = 'diff'\n",
    "model = 'zscore'\n",
    "entry = 'L_Trend'\n",
    "window=25\n",
    "threshold=1.4\n",
    "\n",
    "main(\n",
    "    f\"./data/bybit_candle_btc_{interval}.csv\",\n",
    "    f\"./data/cryptoquant_btc_open-interest_{interval}.csv\",\n",
    "    f\"./data/cryptoquant_btc_netflow_{interval}.csv\",\n",
    "    factor,\n",
    "    factor2,\n",
    "    interval,\n",
    "    operation,\n",
    "    preprocess,\n",
    "    model,\n",
    "    entry,\n",
    "    window,\n",
    "    threshold\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybotrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
